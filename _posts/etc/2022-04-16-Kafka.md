---
layout: post
title: Kafka
tags: [study, etc, kafka]
comments: true
permalink: /etc/Kafka
---

- Kafka?
  - 파편화된 데이터 파이프라인을 안정적인 서비스 운영을 목적으로 개선하기 위하여 개발됨
  - 파편화된 데이터 파이프라인의 복잡도를 낮추기 위함
  - 각각의 애플리케이션끼리 연결하여 데이터를 처리하는것이 아닌 중앙집중화 하여 관리
  - 기존의 1:1매칭되어 높은 의존도를 낮춤
  - FIFO 방식의 큐 자료구조와 유사
  - 엄청난 양의 데이터를 안전하고 빠르게 처리
  - 데이터를 추출, 변경, 적재하는 과정을 묶은 데이터 파이프라인 구축

--------------------------

- Kafka 장점
  - 높은 처리량
    - 카프카는 프로듀서가 브로커로 데이터를 보낼 때, 컨슈머가 브로커로부터 데이터를 받을 때 모두 묶어서 전송한다.
    - 동일한 양의 데이터를 보낼 때 네트워크 통신 횟수를 최소한으로 줄인다.
  - 확장성
    - 데이터 파이프라인에서 데이터를 모을 때 데이터가 얼마나 들어올지 예측하기 어려움
    - 가변적인 환경에서 안정적으로 확장 가능하도록 설계되어있다.
    - 데이터가 적을 때는 카프카 크러스터의 브로커를 최소한으로 운영, 많아지면 클러스터의 브로커 개수를 늘려 스케일 아웃 가능
  - 영속성
    - 데이터를 생성한 프로그램이 종료되더라도 데이터는 사라지지 않는다.
    - 다른 메시징 플랫폼과는 다르게 전송받은 데이터를 메모리에 저장하지 않고 파일 시스템에 저장한다.
    - 페이지 캐시 메모리 영역을 사용하여 한번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용하는 방식이기 때문에 카프카가 파일 시스템에 저장하고 데이터를 저장, 전송하여도 처리량이 높다.
  - 고가용성
    - 3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하여도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다.
    - 클러스터로 이루어진 카프카는 데이터의 복제(replication)를 통해 고가용성의 특징을 가진다.
    - 한 브로커에 장애가 발생하더라도 복제된 데이터가 나머지 브로커에 저장되어 있으므로 저장된 데이터를 기준으로 지속적으로 데이터 처리가 가능하다.

--------------------------

- Kafka 실행 실습
  1. aws 프리티어 사용
     1. ec2 Amazon Linux AMI, SSD Volume Type 선택
     2. 인바운드 보안규칙에 카프카 기본 포트 9092, 주키퍼 기본포트 2181 추가
     3. ssh key 다운로드
<br/><br/>
  2. ec2 인스턴스 접속
     1. 다운받은 ssh key 접근권한 설정 
        - `$ chmod 400 kafka-server-key.pem`
     2. 인스턴스 접속
        - `$ ssh -i kafka-server-key.pem ec2-user@인스턴스 퍼블릭 ip`
<br/><br/>
  3. 인스턴스에 자바 설치
     1. 카프카 브로커를 실행하기 위해 jdk 설치
        - `$ sudo yum install -y java-1.8.0-openjdk-devel.x86_64`
     2. 설치 확인
        - `$ java -version`
<br/><br/>
  4. 카프카 바이너리 패키지 다운로드
     1. https://www.apache.org/dyn/closer.cgi?path=/kafka/3.1.0/kafka_2.12-3.1.0.tgz
     2. HTTP 하단 url 복사하여 다운로드 실행
        - `$ wget https://dlcdn.apache.org/kafka/3.1.0/kafka_2.12-3.1.0.tgz`
     3. 다운받은 바이너리 패키지 압축 해제
        - `$ tar xvf kafka_2.12-3.1.0.tgz`
<br/><br/>
  5. 카프카 브로커 힙 메모리 설정
     1. 카프카 브로커는 레코드의 내용은 페이지 캐시로 시스템 메모리를 사용하고, 나머지 객체들을 힙 메모리에 저장하여 사용한다.
     2. 카프카 브로커를 운영할 때 힙 메모리를 5GB 이상으로 설정하지 않는다.
     3. 카프카 패키지의 힙 메모리는 카프카 브로커 1G, 주키퍼 512MB로 기본 설정되어 있다.
     4. 실습용으로 생성한 프리티어 ec2는 1G 메모리를 가지고 있으므로, 힙 메모리 사이즈를 미리 환경변수로 지정해둔다.
     5. export 명령어로 환경변수 설정
        - `$ export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"`
     6. 설정 확인
        - `$ echo $KAFKA_HEAP_OPTS`
     7. 터미널에서 사용자가 설정한 환경변수는 터미널 세션이 종료되고나면 초기화된다. ~/.bashrc 파일에 해당 설정을 추가하여 쉘 실행시 자동으로 설정되도록 한다.
        - `$ vi ~/.bashrc`
        - `exrpot KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"` 명령어 추가
        - `source ~/.bashrc` 수정된 내용 바로 반영
<br/><br/>
  6. 카프카 브로커 실행 옵션 설정
     1. `$ vi config/server.properties`
     2. advertised.listner 주석 해제, ip 설정
        - 카프카 클라이언트 또는 커맨드 라인 툴을 브로커와 연결할 때 사용
        - 카프카 클라이언트 또는 카프카 커맨드 라인 툴에서 접속할 때 사용하는 IP, port 정보
        - `advertised.listners=PLAINTEXT://인스턴스 퍼블릭 ip:9092`
<br/><br/>
  7. 주키퍼 실행
     1. 카프카 바이너리가 포함된 폴더에는 브로커와 같이 실행할 주키퍼가 준비되어 있다.
     2. 분산 코디네이션 서비스를 제공하는 주키퍼는 카프카의 클러스터 설정 리더 정보, 컨트롤러 정보를 담고 있어 카프카를 실행하는 데에 필요한 필수 애플리케이션이다.
     3. 주키퍼를 1대만 사용하는 것은 비정상적인 운영, 현재는 단순 테스트용이기 때문에 1대만 사용
     4. -daemon 옵션과 주키퍼 설정경로(config/zookeper.properties)와 함께 주키퍼 시작 스크립트(bin/zookeper-server-start.sh)를 실행하면 주키퍼를 백그라운드에서 실행할 수 있다.
        - `$ bin/zookeper-server-start.sh -daemon config/zookeper.properties`
     5. 주키퍼 정상 실행 확인
        - `$ jps -vm`
<br/><br/>
  8. 카프카 브로커 실행
     - `$ bin/kafka-server-start.sh -daemon config/server.properties`
<br/><br/>
  9. 로컬 컴퓨터에서 카프카와 통신 확인(카프카 정보 요청)
     1. 로컬 컴퓨터에 카프카 바이너리 패키지 다운로드
        - `$ curl https://dlcdn.apache.org/kafka/3.1.0/kafka_2.12-3.1.0.tgz --output kafka.tgz`
     2. 압축해제
        - `$ tar -xvf kafka.tgz`
     3. 카프카 브로커에 대한 정보를 가져올 수 있는 명령어를 제공하는 kafka-broker-api-version.sh를 실행하여 정상연동 확인
        - `$ bin/kafka-broker-api-version.sh --bootstrap-server 인스턴스 퍼블릭 ip:9092`
<br/><br/>
  10. 테스트 편의를 위한 hosts 설정(mac os)
      - `$ sudo vim /private/etc/hosts`
      - `인스턴스 퍼플릭 ip my-kafka` 내용 추가